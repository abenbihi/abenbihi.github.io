<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>Box Matching</title>
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <meta name="Description" content="Assia Benbihi, personal website">
       
        <link rel="stylesheet"
              href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
              integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
              crossorigin="anonymous">
        <link rel="stylesheet"
              href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css"> 

        <link rel="stylesheet"
              href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

        <style>
@import url(https://fonts.googleapis.com/css?family=Raleway:400,700);
body, input, select, textarea {font-family: "Raleway", Arial, Helvetica, sans-serif; font-size: 12pt; font-weight: 400; line-height: 1.6em;}
a			{color: #4285F4}
nav a             {color: white}
nav a:hover       {color: white}
h4                {color: #1a60a2}
h5                {color: #1a60a2}
strong	        {color: #1a60a2; font-weight:400}
ol.pubs		{list-style-type: decimal; padding-left: 2em}
ul.pub		{list-style:none; margin-bottom:1em}
ul.pub		{list-style:none; margin-bottom:1em}
ul.pub li.title	{color: #333333}
ul.pub li.authors {color: #555555}
ul.pub li.venue	{font-style: italic}
ul.pub li.venue a {text-decoration: none}
.header           {background-color:#DADADA; margin-bottom:5px}
.card             {border:none}
.container         {margin-top: 1em}
:target {display: block; position: relative; top: -120px; visibility: hidden;}
        </style>

        <meta name="description" content="Updates: 2020-08-21: I managed to get a converging model for window detection although there is significant room for improvement on the..." />
</head>


<body id="index" class="home">
<section id="content" class="body">
  <article>
  <div class="container">
    <div class="row">
      <div class="col">
        <div class="media">
          <div class="media-body">
            <center><h1 class="sticky-top" style="color:#4285F4;">
                Box Matching</h1></center>
          </div>
        </div>
      </div>
    </div>

    <div class="entry-content">
      <h4>Updates:</h4>
<ul>
<li><strong>2020-08-21</strong>: I managed to get a converging model for window detection although
  there is significant room for improvement on the performance (see )
  . I am pausing
  the box detection training to get the localization pipeline running.</li>
<li>2020-08-14: I reduced the problem to its 'simplest version' which is window
  detection. I rely on the OpenImage dataset from which I extract all images
  with box windows annotations. This provides roughly 35000 but there are many
  junk images (approximately 90% of them are trash). So I am cleaning these
  window images and there are now 5000 clean images and half of the OID dataset
  still needs cleaning.</li>
<li>2020-08-07: The RCNN does not converge. When train simulatenously with the
  RPN, it destroys the RPN weights. When the RPN is fixed, the RCNN converges
  to poor performance weights (less than 5% mAP, even on windows). 
  <strong>I am taking a break from this until next time.</strong></li>
<li>2020-07-31: RPN (Region Proposal Network) can be trained on the OID dataset
  that holds mostly windows. The recall-over-IoU metric to evaluate the RPN
  indicates reasonnable performance (cf Fig 3.) although there is still room for
  improvement. Next week, I will train the RCNN.</li>
<li>2020-07-24: Fig4: Integration of useful classes/images from the OpenImage
  dataset (clocks, windows, door, sculptures, fountain). Window detection seems
  fine but I do not know how to interepret the numerical performance.</li>
<li>2020-07-17: SfM annotation ongoing. Scenes from the same landmarks have been
  isolated to avoid redundant annotation. There are approximately 1500 landmarks.
  Their usability depends on the quality of the 3D points cloud (this is being
  assessed). The pipeline is updated daily for any new edge case. </li>
<li>2020-07-01: Phototourism annotation completed. Box detection trained on
  overfitting data runs correctly. Overfitting data is made of a valiation set
  with images different from the training ones but that depict the same scene as the
  training images. Quantitative metrics code is ok.</li>
<li>2020-06-12: Update box annotation propagation to make them tighter around the
  object of interest and to take into account the occlusion.</li>
<li>2020-05-27: Update stereo-matching metrics plot.
  The coarse homography is estimated from putative box matches based on their
  semantic labels and their visual similarity measured with the HardNet
  descriptor. At most 2 matches are kept for each box. Boxes around windows are
  discarded. Degenerate homographies are discarded early in the process.
  The computational time has been speeded up at the cost of less confidence on
  the homography (this needs to be quantified). Next step: Identify edge cases
  for the stereo-matching.</p></li>
<li>2020-05-15: Update stereo-matching metrics plot with full sacre-coeur
  results. The box matching is being improved to reduce the number of putative
  box matches that causes major latency by adding constraints on the boxes'
  geometric layout (e.g. putative matching boxes should form a simple polygon
  in both images).</p></li>
<li>2020-05-10: first commit</li></li>
</ul>
<h4>TODO:</h4>
<ol>
<li><s>Speed up the box matching.</s> One way to do so is to reduce the initial set of
  putative matches or to define a ransac threshold above which the estimated coarse
  image transformation is satisfying.</li>
<li><s>Integrate visual similarity when sampling putative match.</s>
  Refine the putative box matching: currently, boxes are matched based on their
  semantic consistency only which leads to a high number of matches. It is
  possible to add a visual similarity constraint between boxes with the same
  label by computing a descriptor over the box and match them only if the
  descriptor distance is below a threshold. Tune this threshold.</li>
<li>Debug the metric code.</li>
<li>Manually annotate the boxes</li>
<li>Define the box annotation granularity i.e. to which architectural specificity
  the annotations go down to?</li>
<li>Identify stereo-matching edge cases and solve them.</li>
<li>Implement the localization evaluation.</li>
</ol>
<p>Finding local correspondences among cluttered scenes requires identifying the
image's regions to match. Current approaches based on saliency or semantics
provide only coarse and few such regions per image. I propose to identify
regions to match at a finer level, for example at the level of an object.
Matching these finer regions allows computing a coarse image transformation
later used to constrain the local correspondences. </p>
<p>Current experiments involve the Phototourism dataset where regions of interest
are doors, windows, statues ... Manual annotations of such regions are
collected in the form of semantic boxes. The annotation effort is reduced by
taking advantage of the dense although incomplete 3d information of the
dataset. These labels are used to train an existing object detector (Faster
R-CNN). In parallel, the region matching is developed using the manual
annotation first. Regions are matched according to their semantics and visual
similarity in an N-to-N fashion.</p>
<p align="center">
<img width="1024" src="/images/box_matching/selected_match.png">
</p>

<p align="center">
An example of semantic boxes on the Phototourism dataset and four putative box matches.
</p>

<h4>Results</h4>
<p>Experiments aim at showing the benefits of the two-stages matching against a
naive matching for stereo-matching and localization. Current results are
computed on the validation set of the phototourism dataset with manual box
annotations. This will be updated to integrate the trained box detector.</p>
<h5>Stereo Matching</h5>
<p>Given a pair of images of the same scenes, the goal is to recover the camera
displacement.</p>
<p>I measure the accuracy of the camera displacement between image pairs of the
same scene, as in the
<a href="thehttps://vision.uvic.ca/image-matching-challenge/">image-matching-challenge</a>.
Given a set of angular error thresholds, I measure the ratio of image pairs for
which the estimated displacement error falls below each threshold. The area
under this curve is called the mean Average Accuracy (mAA). The set of local
features is fixed (upright-SIFT) and I compare the mAA between a naive matching and
a box-constrained matching.</p>
<p>For one scene, the list of image pairs is the same as in the image-matching
challenge: image pairs are selected with various co-visibility i.e. the amount
of common structures in each image. The current plots are computed only on a
subset of these pairs for computational time considerations (until I speed up
the box matching). The list is made of the 100 pairs for which naive matching
performs the worst.</p>
<p align="center">
<img width="1024" src="/images/box_matching/stereo_plot.png">
</p>

<p align="center">
mAA over images pairs of the three phototourism validation scenes.
(reichstag and st-peters coming soon)
</p>

<h5>Feature-based Localization (coming soon)</h5>
<p>Given a set of reference images of a scene, the goal is to recover the relative
pose of a set of query images of the same scene with respect to the reference
ones. The reference images to construct the 3D of the scene and the query
images are then registered in the scene.</p>
<h4>Box detection</h4>
<h5>Quantitative results (latest)</h5>
<ul>
<li>
<p>Model: Faster R-CNN with Resnet50 backbone</p>
</li>
<li>
<p>Training data: A clean subset of Open Image dataset with the labels listed above.
  Number of images: 4766. Number of windows: 70752.</p>
</li>
<li>Labels: window</li>
<li>
<p>Validation data: A subset of the Open Image dataset.
  Number of images: 200.</p>
</li>
<li>
<p>Metrics: mAP, recall (explicit definition to come once I finally get them)</p>
</li>
<li>
<p>Interpretation: No idea.</p>
</li>
<li>
<p>Metric parameters: maximum number of detections: 300</p>
</li>
<li>Max number of detections: 300</li>
<li>Train model: 318</li>
<li>Train step: 1000</li>
</ul>
<p align="center">
mAP for window detection on OpenImage Dataset.
</p>

<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Metric                </th>
            <th> All     </th>
            <th> </th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> mAP@.50               </td>
                <td> 65.9  </td>
                <td> <br></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@.75               </td>
                <td> 22.2  </td>
                <td> </td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@0.50:0.95         </td>
                <td> 29.9  </td>
                <td> </td>
            </tr>
            <tr>
                <td></td>
                <td> Recall@IoU=0.50:0.95  </td>
                <td> 44.2  </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<h5>Box regression evaluation.</h5>
<p><p align="center">
<img width="512" src="/images/box_matching/step3_recall_over_iou.png">
</p></p>
<p align="center">
Figure 3. Quantitative evaluation of the box locations. Both the RPN and the
RCNN box regression are evaluated with the ratio of groundtruth boxes (recall)
recovered with IoU higher than a threshold specified by the x-axis.  Note that
boxes regressed by the RCNN (which is the second stage box regression) provides
slightly better results. This suggests that this additionnal regression is
relevant.
</p>

<h5>Data Annotation</h5>
<h6>Method</h6>
<p>Manual box annotations are collected over a subset of images depicting the same
scene with different viewpoints. The rest of the images are annotated by
projecting the manual annotations from the previous images using the image pose
and depth. The projection is run only between image pairs with similar
viewpoints to limit the effects of the depth noise. Given a reference image
with manual box annotations and a new image to annotate, the projection is
performed as follow: all the non-occluded pixels inside the manual box are
projected to the new image. The new box is the minimum enclosing box over the
projected points.</p>
<p align="center">
<img width="1100" src="/images/box_matching/box_annotation.png">
</p>

<p align="center">
Box annotation improvement. Left: Naive projection. The corners of the manual
boxes are projected to the new image. This can result in loose boxes and ignore
occlusions.
Right: Improved projection. All the points inside a box are projected to the
second image and the resulting box is the minimum enclosing box over the
majority of projected points.
</p>

<h4>Stats on the never ending annotation of the SfM dataset</h4>
<p align="center">
<img width="1100" src="/images/box_matching/box_semantic_stats.png">
</p>

<p align="center">
Semantic classes distribution. Left: Image distribution per scene. Right: Box
label distribution (only a subset of the labels is currently used for training
although more box labels are being annotated). 
Obvisouly, windows are overly-represented (to my utter despair).
</p>

<h5>Detailed label distribution per scene (simple label list)</h5>
<p>This is useful to know how to pick the scenes to balance the box label
distribution. (And yes, I know the table is ugly but I can not get the mtf css
to do what I want.)</p>
<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Scene                            </th>
            <th> Desc.                            </th>
            <th> # of images  </th>
            <th> window       </th>
            <th> statue       </th>
            <th> tour         </th>
            <th> door         </th>
            <th> dome         </th>
            <th> frontont     </th>
            <th> horloge      </th>
            <th> balcony      </th>
            <th> rosace       </th>
            <th> pillar       </th>
            <th></th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> cmp_facades_base                 </td>
                <td> Facade                           </td>
                <td> 378          </td>
                <td> 12222        </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 398          </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 1118         </td>
                <td> 0            </td>
                <td> 4899         </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> cmp_facades_extended             </td>
                <td> Facade                           </td>
                <td> 228          </td>
                <td> 7817         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 224          </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 753          </td>
                <td> 0            </td>
                <td> 2269         </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> brandenburg_gate                 </td>
                <td> Arch                             </td>
                <td> 1359         </td>
                <td> 317          </td>
                <td> 1181         </td>
                <td> 0            </td>
                <td> 285          </td>
                <td> 0            </td>
                <td> 448          </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 7492         </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> buckingham_palace                </td>
                <td> Facade and fountain              </td>
                <td> 1676         </td>
                <td> 31172        </td>
                <td> 1038         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 2085         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 5832         </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> notre_dame_front_facade          </td>
                <td> Facade                           </td>
                <td> 3752         </td>
                <td> 22735        </td>
                <td> 92557        </td>
                <td> 4623         </td>
                <td> 6254         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 9132         </td>
                <td> 0            </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> pantheon_exterior                </td>
                <td> Facade                           </td>
                <td> 1389         </td>
                <td> 0            </td>
                <td> 698          </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 1258         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 7442         </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> taj_mahal                        </td>
                <td> Facade                           </td>
                <td> 1312         </td>
                <td> 7274         </td>
                <td> 0            </td>
                <td> 3947         </td>
                <td> 0            </td>
                <td> 7661         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> trevi_fountain                   </td>
                <td> Facade                           </td>
                <td> 3191         </td>
                <td> 18395        </td>
                <td> 13255        </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 2912         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 19300        </td>
                <td> 0            </td>
                <td> 17517        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> westminster_abbey                </td>
                <td> Front and Side Facade.           </td>
                <td> 1058         </td>
                <td> 5492         </td>
                <td> 3384         </td>
                <td> 0            </td>
                <td> 1756         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 791          </td>
                <td> 0            </td>
                <td> 3886         </td>
                <td> 7            </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> casa_mila-17217-0                </td>
                <td> Facade.                          </td>
                <td> 1639         </td>
                <td> 10462        </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 3900         </td>
                <td> 0            </td>
                <td> 709          </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> casa_baltllo-8296-1              </td>
                <td> Facade.                          </td>
                <td> 250          </td>
                <td> 188          </td>
                <td> 0            </td>
                <td> 11           </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 257          </td>
                <td> 0            </td>
                <td> 4            </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> paris_opera-13418-0              </td>
                <td> Facade.                          </td>
                <td> 214          </td>
                <td> 0            </td>
                <td> 178          </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 224          </td>
                <td> 0            </td>
                <td> 768          </td>
                <td> 0            </td>
                <td> 406          </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> versailles-16576-0               </td>
                <td> Garden facade.                   </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td>              </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> Total                            </td>
                <td>                                  </td>
                <td> 14440        </td>
                <td> 116074       </td>
                <td> 112291       </td>
                <td> 8581         </td>
                <td> 8917         </td>
                <td> 10573        </td>
                <td> 4015         </td>
                <td> 791          </td>
                <td> 26096        </td>
                <td> 13018        </td>
                <td> 46577        </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Scene                            </th>
            <th> Desc.                            </th>
            <th> # of images  </th>
            <th> window       </th>
            <th> statue       </th>
            <th> tour         </th>
            <th> door         </th>
            <th> dome         </th>
            <th> frontont     </th>
            <th> horloge      </th>
            <th> balcony      </th>
            <th> rosace       </th>
            <th> pillar       </th>
            <th></th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> reichstag                        </td>
                <td> Facade                           </td>
                <td> 75           </td>
                <td> 2013         </td>
                <td> 269          </td>
                <td> 720          </td>
                <td> 0            </td>
                <td> 72           </td>
                <td> 71           </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 1117         </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> sacre_coeur                      </td>
                <td> Facade                           </td>
                <td> 1174         </td>
                <td> 8405         </td>
                <td> 3004         </td>
                <td> 4053         </td>
                <td> 100          </td>
                <td> 2098         </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 0            </td>
                <td> 338          </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> st_peters_square                 </td>
                <td> Facade                           </td>
                <td> 2491         </td>
                <td> 31226        </td>
                <td> 23645        </td>
                <td> 1808         </td>
                <td> 12250        </td>
                <td> 1470         </td>
                <td> 1963         </td>
                <td> 3497         </td>
                <td> 5741         </td>
                <td> 0            </td>
                <td> 21785        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> Total                            </td>
                <td>                                  </td>
                <td> 3239         </td>
                <td> 41644        </td>
                <td> 26918        </td>
                <td> 6581         </td>
                <td> 12350        </td>
                <td> 3640         </td>
                <td> 2034         </td>
                <td> 3497         </td>
                <td> 5741         </td>
                <td> 0            </td>
                <td> 23240        </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<!--#### Setup

#### Dataset
Annotation progress on the [Phototourism](https://vision.uvic.ca/imw-challenge/index.md) dataset.

| Scene name              | Split | Size  | Annotated  |
| ----------------------- | :---: | :---: | :--------: |
| reichstag               | val   | 75    |     x     |   
| sacre_coeur             | val   | 1179  |     x     |
| st_peters_square        | val   | 2504  |     x     |
| brandenburg_gate        | train | 1363  |           |
| buckingham_palace       | train | 1676  |           |
| colosseum_exterior      | train | 2063  |           |
| grand_place_brussels    | train | 1083  |           |
| hagia_sophia_interior   | train | 889   |           |
| notre_dame_front_facade | train | 3765  |           |
| palace_of_westminster   | train | 983   |           |
| pantheon_exterior       | train | 1401  |           |
| prague_old_town_square  | train | 2316  |           |
| taj_mahal               | train | 1312  |           |
| temple_nara_japan       | train | 904   |           |
| trevi_fountain          | train | 3191  |           |
| westminster_abbey       | train | 1061  |           |-->

<h5>Quantitative results (outdated)</h5>
<ul>
<li>
<p>Model: Faster R-CNN with Resnet50 backbone</p>
</li>
<li>
<p>Training data: A subset of Open Image dataset with the labels listed above.
  Number of images: 39000</p>
</li>
<li>Labels: window, door, statue, fountain, clock</li>
<li>
<p>Validation data: A subset of the Phototourism validation scenes (st peters
  square, sacre coeur, reichstag). Groundtruth annotations are collected
  manually. Number of images: 1155.</p>
</li>
<li>
<p>Metrics: mAP, recall (explicit definition to come once I finally get them)</p>
</li>
<li>
<p>Interpretation: A better idea than before but I still need to put words on it.</p>
</li>
<li>
<p>Metric parameters: maximum number of detections: 300</p>
</li>
<li>Max number of detections: 300</li>
<li>Train model: 205</li>
<li>Train step: 60000</li>
</ul>
<p align="center">
Metrics over all validation scenes (st peters square, sacre coeur, reichstag)
</p>

<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Metric                </th>
            <th> All   </th>
            <th> Window  </th>
            <th> Door  </th>
            <th> Statue  </th>
            <th> Clock </th>
            <th> Fountain  </th>
            <th></th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> mAP@.50               </td>
                <td> 10.8  </td>
                <td> 22.4    </td>
                <td> 29.0  </td>
                <td>  0.7    </td>
                <td>  0    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@.75               </td>
                <td> 0.9   </td>
                <td> 2.1     </td>
                <td> 1.2   </td>
                <td>  0.0    </td>
                <td>  0    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@0.50:0.95         </td>
                <td> 3.2   </td>
                <td> 7.1     </td>
                <td> 7.5   </td>
                <td>  0.1    </td>
                <td>  0    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> Recall@IoU=0.50:0.95  </td>
                <td> 12.6  </td>
                <td> 20.4    </td>
                <td> 25.7  </td>
                <td>   5     </td>
                <td>  0    </td>
                <td> NA        </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<p align="center">
St Peters Square Metrics
</p>

<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Metric                </th>
            <th> Window  </th>
            <th> Door  </th>
            <th> Statue  </th>
            <th> Clock </th>
            <th> Fountain  </th>
            <th></th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> mAP@.50               </td>
                <td> 29.4    </td>
                <td> 36.2  </td>
                <td>   0.5   </td>
                <td>  NA   </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@.75               </td>
                <td> 2.2     </td>
                <td> 1.6   </td>
                <td>   0     </td>
                <td>  NA   </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@0.50:0.95         </td>
                <td> 9.3     </td>
                <td> 9.5   </td>
                <td>   0.1   </td>
                <td>  NA   </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> Recall@IoU=0.50:0.95  </td>
                <td> 23.7    </td>
                <td> 25.9  </td>
                <td>   1.6   </td>
                <td>  NA   </td>
                <td> NA        </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<p align="center">
Sacre Coeur Metrics
</p>

<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Metric                </th>
            <th> Window  </th>
            <th> Door  </th>
            <th> Statue  </th>
            <th> Clock </th>
            <th> Fountain  </th>
            <th></th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> mAP@.50               </td>
                <td>  13.1   </td>
                <td>  NA   </td>
                <td>  2.0    </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@.75               </td>
                <td>  1.5    </td>
                <td>  NA   </td>
                <td>  0      </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@0.50:0.95         </td>
                <td>  4.0    </td>
                <td>  NA   </td>
                <td>  0.4    </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> Recall@IoU=0.50:0.95  </td>
                <td>  15.9   </td>
                <td>  NA   </td>
                <td>  16.6   </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<p align="center">
Reichstag Metrics
</p>

<p>
<div class="bs-component">
    <table class="table table-hover">
        <thead>
        <tr>
            <th></th>
            <th> Metric                </th>
            <th> Window  </th>
            <th> Door  </th>
            <th> Statue  </th>
            <th> Clock </th>
            <th> Fountain  </th>
            <th></th>
        </tr>
        </thead>
        <tbody>
            <tr>
                <td></td>
                <td> mAP@.50               </td>
                <td>  20.2   </td>
                <td> NA    </td>
                <td>   NA   </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@.75               </td>
                <td>  2.0    </td>
                <td> NA    </td>
                <td>   NA   </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> mAP@0.50:0.95         </td>
                <td>  6.3    </td>
                <td> NA    </td>
                <td>   NA   </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
            <tr>
                <td></td>
                <td> Recall@IoU=0.50:0.95  </td>
                <td>  15.7   </td>
                <td> NA    </td>
                <td>   NA   </td>
                <td>   NA    </td>
                <td> NA        </td>
                <td></td>
            </tr>
        </tbody>
    </table>
</div></p>
<h5>RPN evaluation</h5>
<p><p align="center">
<img width="1024" src="/images/box_matching/recall_over_iou.png">
</p></p>
<p align="center">
Figure 3. Quantitative evaluation on the Region Proposal Network. The RPN is
trained on the OID images and evaluated on the Phototourism evaluation set. The
curves shows the recall over iou i.e. the ratio of boxes identified as
foreground objects that overlap with a specific IoU over a groundtruth box.
Here I plot the curve only after 10 000 training steps (blue) and 100 000
training steps. The RPN is trained only for up to 100 000 steps for now but the
curves suggest that it needs more training.
</p>

<h5>Qualitative results</h5>
<p align="center">
<img width="784" src="/images/box_matching/99368623_945839111.png">
</p>

<p align="center">
Figure 4. Qualitative results on the box detection network. Faster-RCNN with resnet50
backbone is trained on a subset of the OpenImage dataset (39000 images with 155 342 windows and 10716 doors). 
The mAP is still awfully low (<2%) which suggests a bug in the code currently
under investigation.
</p>

<p align="center">
<img width="328" src="/images/box_matching/600.png">
<img width="600" src="/images/box_matching/500.png">
</p>

<p align="center">
Qualitative results on the box detection network. Faster-RCNN with resnet50
backbone is trained on almost all the PhotoTourism scenes (
brandenburg_gate
buckingham_palace
notre_dame_front_facade
pantheon_exterior
taj_mahal
trevi_fountain
westminster_abbey
reichstag
sacrecoeur
st_peters_square)
The training and validation sets are made of different images but they depict
the same scene. Such a split is useful to made the network overfit before the
training and evaluation of the final data.

The images show that the network can indeed converge (even on small objects).
Now, it must be better tuned and fed more data to increase the performances.
(For bigger images, contact me.)
</p>
    </div><!-- /.entry-content -->
  </div>


  </article>
</section>

<script type="text/javascript">
    var disqus_shortname = 'abenbihi-github-io';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>